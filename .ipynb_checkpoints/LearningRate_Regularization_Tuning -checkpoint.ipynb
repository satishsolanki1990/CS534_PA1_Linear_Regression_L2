{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore Warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#to see all the columns\n",
    "pd.set_option('display.max_columns',30) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv(\"PA1_train.csv\")\n",
    "dev = pd.read_csv(\"PA1_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "eps = 0.5\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ID feature\n",
    "train.drop('id',axis=1,inplace=True)\n",
    "dev.drop('id',axis=1,inplace=True)\n",
    "\n",
    "# Split the date\n",
    "for df in [train,dev]:\n",
    "    df['month'] = df.date.map(lambda x : x.split('/')[0])\n",
    "    df['day'] = df.date.map(lambda x : x.split('/')[1])\n",
    "    df['year'] = df.date.map(lambda x : x.split('/')[2]).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tables (statistics)\n",
    "num = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors',\\\n",
    "       'view','sqft_above','sqft_basement','yr_built','yr_renovated'\\\n",
    "       ,'lat','long','sqft_living15','sqft_lot15']\n",
    "cat = ['waterfront','condition','grade']\n",
    "table1 = pd.DataFrame({'Feature':num,'Mean':train[num].mean(),\\\n",
    "              'Standard deviation':train[num].std(),\\\n",
    "             'Range':train[num].max()-train[num].min()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in cat:\n",
    "    n = train[cat].nunique().max()-train[cat].nunique()[i]\n",
    "    d[i.capitalize()+ \" categories\"] = list(train[i].value_counts(normalize=True).index)+[' ']*n\n",
    "    d[i[0]+\" %\"] = list(train[i].value_counts(normalize=True)*100)+[' ']*n\n",
    "table2 = pd.DataFrame(d)\n",
    "#table1.to_excel('table1.xlsx',index=False)# in report\n",
    "#table2.to_excel('table2.xlsx',index=False)# in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train,dev]:\n",
    "    df.drop('date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization\n",
    "# We save copies of the non normalized datasets for part 3\n",
    "train_raw = train.copy()\n",
    "dev_raw = dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure we have numerical features for part 3 :\n",
    "for df in [train_raw,dev_raw]:\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].map(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(train.columns)\n",
    "cols.remove('price')\n",
    "cols.remove('dummy')\n",
    "for col in cols:\n",
    "    train[col] = train[col].map(float)\n",
    "    dev[col] = dev[col].map(float)\n",
    "    test[col] = test[col].map(float)\n",
    "    M = train[col].max()\n",
    "    m = train[col].min()\n",
    "    train[col] = train[col].map(lambda x : (x-m)/(M-m))\n",
    "    dev[col] = dev[col].map(lambda x : (x-m)/(M-m))\n",
    "    test[col] = test[col].map(lambda x : (x-m)/(M-m))\n",
    "train.price = train.price.map(float)\n",
    "M = train.price.max()\n",
    "m = train.price.min()\n",
    "train['normalized_price'] = train.price.map(lambda x : (x-m)/(M-m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(train,dev,gamma,max_it,lambdA):\n",
    "    t = time.time()\n",
    "    y = np.transpose(np.array(train.normalized_price,ndmin=2))\n",
    "    y_raw = np.transpose(np.array(train.price,ndmin=2))\n",
    "    X = np.array(train.drop(['price','normalized_price'],axis=1))\n",
    "    features = list(train.drop(['price','normalized_price'],axis=1).columns)\n",
    "    N = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    w = np.random.rand(d,1)\n",
    "    \n",
    "    norm_grad = 100\n",
    "    SSE = []\n",
    "    c = 0\n",
    "    while (norm_grad > eps) & (c < max_it):\n",
    "        error = X.dot(w) - y\n",
    "        grad = 2*np.transpose(X).dot(error)+2*lambdA*w\n",
    "        norm_grad = np.linalg.norm(grad)\n",
    "        w -= gamma*grad\n",
    "        SSE.append(np.linalg.norm(((X.dot(w))*(M-m)+m) - y_raw)**2)\n",
    "        c += 1\n",
    "    # SSE validation :\n",
    "    y_dev = np.transpose(np.array(dev.price,ndmin=2))\n",
    "    X_dev = np.array(dev.drop('price',axis=1))\n",
    "    SSE_dev = X_dev.dot(w)\n",
    "    SSE_dev = np.linalg.norm(((X_dev.dot(w))*(M-m)+m) - y_dev)**2\n",
    "    \n",
    "    # Mean Relative Absolute Error on validation :\n",
    "    MRAE = np.round((pd.Series((((X_dev.dot(w))*(M-m)+m) - y_dev)[:,0]).map(abs)/dev.price).mean(),4)\n",
    "    \n",
    "    elapsed = time.time() - t\n",
    "    return (w,SSE,c,elapsed,SSE_dev,MRAE,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: overflow encountered in multiply\n",
      "  app.launch_new_instance()\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in multiply\n",
      "  app.launch_new_instance()\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "## Part 1 :\n",
    "lambdA = 0\n",
    "max_it = 500000 # we tried with 1M5 for 1e-7 but norm_grad won't get lower\n",
    "gammas = [1e-0,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7]\n",
    "all_c = []\n",
    "final_SSEs_train = []\n",
    "SSEs_validation = []\n",
    "all_MRAE = []\n",
    "SSE_train_curves = []\n",
    "all_w = []\n",
    "for gamma in gammas:\n",
    "    temp = learn(train,dev,gamma,max_it,lambdA)\n",
    "    SSE_train_curves.append(temp[1])\n",
    "    all_c.append(temp[2])\n",
    "    final_SSEs_train.append(temp[1][-1])\n",
    "    SSEs_validation.append(temp[4])\n",
    "    all_MRAE.append(temp[5])\n",
    "    all_w.append(temp[0])\n",
    "    features = temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_part1 = pd.DataFrame({'Gamma':gammas,'iterations':all_c,'SSE training':final_SSEs_train,\\\n",
    "             'SSE validation':SSEs_validation,'MRAE':all_MRAE})\n",
    "#results_part1.to_excel('results_part1.xlsx',index=False)# in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving curves in .csv files to plot them later\n",
    "#temp = 'part1_gamma_1e-'\n",
    "#c = 0\n",
    "#for i in SSE_train_curves:\n",
    "#    name = temp+str(c)\n",
    "#    pd.DataFrame({name:i}).to_csv(name+'.csv',index=False)\n",
    "#    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning weights from the best solution :\n",
    "# the one from gamma = 1e-5\n",
    "weights = pd.DataFrame({'Features':features,'Weights':list(all_w[5][:,0])})\n",
    "weights = weights.sort_values(by='Weights',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights.to_excel('part1_best_w.xlsx',index=False)# in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure in report :\n",
    "#fig = weights.plot(x='Features',y='Weights',kind='bar',rot=80).get_figure()\n",
    "#fig.set_size_inches(16,9)\n",
    "#fig.savefig('part1_best_w.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2 :\n",
    "max_it = 300000\n",
    "gamma = 1e-5\n",
    "lambdas = [0,1e-3,1e-2,1e-1,1,10,100]\n",
    "SSE_train = []\n",
    "SSE_validation = []\n",
    "ws = []\n",
    "for lambdA in lambdas:\n",
    "    temp = learn(train,dev,gamma,max_it,lambdA)\n",
    "    SSE_train.append(temp[1][-1])\n",
    "    SSE_validation.append(temp[4])\n",
    "    ws.append(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_part2 = pd.DataFrame({'Lambda':lambdas,'SSE training':SSE_train,\\\n",
    "             'SSE validation':SSE_validation})\n",
    "#results_part2.to_excel('results_part2.xlsx',index=False)# in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = list(pd.Series(lambdas).map(lambda x : \"lambda = \"+str(x)))\n",
    "d = {'Features':temp[-1]}\n",
    "c = 0\n",
    "for i in li:\n",
    "    d[i] = list(ws[c][:,0])\n",
    "    c += 1\n",
    "part2_w_table = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#part2_w_table.to_excel('part2_w_table.xlsx',index=False)# in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following table is a complementary answer to part2 question (d)\n",
    "# it shows how lambda tend to squeeze the weights close to zero\n",
    "part2_d = pd.DataFrame(abs(part2_w_table.iloc[:,1:]).sum())\n",
    "#part2_d.to_excel('part2_d.xlsx')# in report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_part_3(train,dev,gamma,max_it):\n",
    "    y = np.transpose(np.array(train.price,ndmin=2))\n",
    "    X = np.array(train.drop('price',axis=1))\n",
    "    N = X.shape[0]\n",
    "    d = X.shape[1]\n",
    "    w = np.random.rand(d,1)\n",
    "    \n",
    "    norm_grad = 100\n",
    "    SSE = []\n",
    "    SSE_dev = []\n",
    "    c = 0\n",
    "    while (norm_grad > eps) & (c < max_it):\n",
    "        error = X.dot(w) - y\n",
    "        grad = 2*np.transpose(X).dot(error)\n",
    "        norm_grad = np.linalg.norm(grad)\n",
    "        w -= gamma*grad\n",
    "        SSE.append(np.linalg.norm(X.dot(w) - y)**2)\n",
    "        c += 1\n",
    "        # SSE validation :\n",
    "        y_dev = np.transpose(np.array(dev.price,ndmin=2))\n",
    "        X_dev = np.array(dev.drop('price',axis=1))\n",
    "        SSE_dev.append(np.linalg.norm(X_dev.dot(w) - y_dev)**2)\n",
    "        \n",
    "    return (w,SSE,c,SSE_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in multiply\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "max_it = 10000\n",
    "gammas = [1,0,1e-3,1e-6,1e-9,1e-15]\n",
    "SSEt = []\n",
    "SSEv = []\n",
    "for gamma in gammas:\n",
    "    temp = learn_part_3(train_raw,dev_raw,gamma,max_it)\n",
    "    SSEt.append(temp[1])\n",
    "    SSEv.append(temp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = list(pd.Series(gammas).map(lambda x : 'part3_gamma_'+str(x)))\n",
    "c = 0\n",
    "for i in li:\n",
    "    table = pd.DataFrame({'SSE training':SSEt[c],'SSE validation':SSEv[c]})\n",
    "    c += 1\n",
    "    #table.to_csv(i,index=False)# curves in the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction on test dataset\n",
    "\n",
    "# Best w from our experiment :\n",
    "# the one with gamma = 1e-5 and lambda = 1e-3\n",
    "# SSE on validation was 21316.6 for these parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ws[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(test.drop('id',axis=1))\n",
    "y_pred = (X.dot(w))*(M-m)+m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predicted_price'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we decide to apply a little correction for the predicted price :\n",
    "# a few houses were priced by our model at a negative price,\n",
    "# which does not make sense.\n",
    "# In order to have a good score on the test set the idea was to bypass\n",
    "# the model for these \"obvious\" mistakes.\n",
    "# We went up to 50k house (arbitrary decision), so that it makes sense.\n",
    "test.predicted_price = np.where(test.predicted_price < 0.5,0.5,test.predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[['id','predicted_price']].to_csv('prediction.csv',index=False)# .csv file sent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
